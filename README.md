
## Demo

![Olist demo](assets/videos/Olist-demo.gif)

# Olist Ecommerce Analytics â€” Azure Databricks + Power BI

**End-to-end retail analytics on the public Olist dataset.**  
Ingest & model in **Azure Databricks**, store curated data in **Azure Blob (SAS)**, and deliver insights with **Power BI** (KPI, **RFM segmentation**, drill-through).

> âš ï¸ All secrets are **redacted**. Replace placeholders with your own credentials (Databricks **Secret Scope** or environment variables).

---

## TL;DR

- â­ **Business:** growth levers via **RFM cohorts**, top sellers/customers/categories, YoY trends.  
- ğŸ› ï¸ **Tech:** Notebooks â†’ **star schema** â†’ PBIX; fast visuals; RLS sanity page.  
- â±ï¸ **60-sec demo:** open `powerbi/Olist-Dashboard.pbix`, point to `data/*/*.csv`, **Refresh**.


---


### Dashboards (screenshots)

<p align="center">
  <img src="assets/dashboards/Performance_overview.png" width="45%"/>
  <img src="assets/dashboards/Performance_overview2.png" width="45%"/>
</p>

<p align="center">
  <img src="assets/dashboards/Customer_segmentation%20(RFM).png" width="45%"/>
  <img src="assets/dashboards/drillthrough%201%20seller%20insight.png" width="45%"/>
</p>

<p align="center">
  <img src="assets/dashboards/drillthrough%202%20customers%20performance.png" width="45%"/>
  <img src="assets/dashboards/drillthrough3%20Productcategory%20details.png" width="45%"/>
</p>

<p align="center">
  <img src="assets/dashboards/RLS%20check1.png" width="45%"/>
  <img src="assets/dashboards/RLS%20check2.png" width="45%"/>
</p>




## Repository structure

â”œâ”€ databricks/
â”‚ â”œâ”€ notebooks/
â”‚ â”‚ â”œâ”€ etl_olist.py # exported & sanitized notebook
â”‚ â”‚ â””â”€ sql/ # (optional) SQL exports
â”‚ â””â”€ README.md # how to import/run in Databricks
â”œâ”€ data/ # optional local star-schema CSVs
â”‚ â”œâ”€ FactOrders/FactOrders.csv
â”‚ â”œâ”€ DimCustomer/DimCustomer.csv
â”‚ â”œâ”€ DimProduct/DimProduct.csv
â”‚ â”œâ”€ DimSeller/DimSeller.csv
â”‚ â””â”€ DimDate/DimDate.csv
â”œâ”€ powerbi/
â”‚ â””â”€ Olist-Dashboard.pbix
â”œâ”€ assets/
â”‚ â”œâ”€ azure/ # redacted infra screenshots
â”‚ â”œâ”€ databricks/ # notebook screenshots
â”‚ â””â”€ dashboards/ # page screenshots
â””â”€ docs/ # deep dives (engineering, model, RFMâ€¦)


---

## Architecture

**Raw (Blob/SAS) â†’ Curated (Star schema in Databricks) â†’ BI (Power BI)**  


---

## Quickstart

### Option A â€” Local (no Azure needed)

1. Clone this repo.  
2. Open **`powerbi/Olist-Dashboard.pbix`**.  
3. If prompted, browse to `data/*/*.csv` and **Refresh**.

### Option B â€” Full pipeline (Azure)

1. Create an Azure Storage Account & container `olist-raw` (HTTPS-only SAS).  
2. Import `databricks/notebooks/etl_olist.py` into Databricks.  
3. Store your SAS in a **Secret Scope** and run the notebook to export the star schema back to Blob.  
4. Open the PBIX and connect to those CSVs (Blob or local copy).

## Azure proofs (redacted)

<p align="center">
  <img src="assets/azure/azure-sas-settings.png" width="45%"/>
  <img src="assets/azure/azure-containers-list.png" width="45%"/>
</p>

<p align="center">
  <img src="assets/azure/azure-csv_data.png" width="45%"/>
</p>



** Data Source:** Public Olist e-commerce dataset (Brazil).  
This repo includes the curated **star-schema CSVs** (FactOrders, DimCustomer, DimProduct, DimSeller, DimDate) for local demo.  
Please check the original dataset license for re-use and attribution guidelines.


Example (sanitized):

```python
# NOTE: the real token is stored in a Secret Scope in Databricks.
# sas_token = dbutils.secrets.get(scope="olist-secrets", key="adls-sas")
sas_token = "<SAS_AT_RUNTIME>"
account   = "olistdatalake2025"
container = "olist-raw"

spark.conf.set(
    f"fs.azure.sas.{container}.{account}.blob.core.windows.net",
    sas_token
)


